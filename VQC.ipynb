{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ada0906b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import NesterovMomentumOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c3d946ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_wires=4\n",
    "dev = qml.device(\"default.qubit\", wires=num_wires)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c9f7e0",
   "metadata": {},
   "source": [
    "Variational classifiers usually define a “layer” or “block”, which is an elementary circuit architecture that gets repeated to build the full variational circuit.\n",
    "\n",
    "Our circuit layer will use four qubits, or wires, and consists of an arbitrary rotation on every qubit, as well as a ring of CNOTs that entangles each qubit with its neighbour. Borrowing from machine learning, we call the parameters of the layer weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "365f1e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(layer_weights):\n",
    "    for wire in range(4):\n",
    "        qml.Rot(*layer_weights[wire], wires=wire)   \n",
    "    \n",
    "    for wire in ([0,1],[1,2],[2,3],[3,0]):\n",
    "        qml.CNOT(wire)  #aplyinh CNOT gates to adjacent gates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5b99cf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_prep(x):\n",
    "    qml.BasisState(x, wires=[0,1,2,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a13787b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev)\n",
    "\n",
    "def circuit(wieghts,x):\n",
    "    state_prep(x)\n",
    "    \n",
    "    for layer_weights in weights:\n",
    "        layer(layer_weights)\n",
    "    \n",
    "    return qml.expval(qml.PauliZ(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bb6b44",
   "metadata": {},
   "source": [
    "If we want to add a “classical” bias parameter, the variational quantum classifier also needs some post-processing. We define the full model as a sum of the output of the quantum circuit, plus the trainable bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "bdb48d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variational_calssifier(weights, bias, x):\n",
    "    return circuit(weights,x) + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f023c3f9",
   "metadata": {},
   "source": [
    "Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d077b2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_loss(labels, predictions):\n",
    "    return np.mean((labels-qml.math.stack(predictions))**2)   #loss\n",
    "\n",
    "def acc(labels, predictions):\n",
    "    accu = sum(abs(l-p) <2 for l,p in zip(labels, predictions))   #accuracy\n",
    "    accu =accu/len(labels)\n",
    "    return accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8a28f7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(weights, bias, X,Y):\n",
    "    predictions = [variational_calssifier(weights,bias, x) for x in X]\n",
    "    return square_loss(Y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "75431dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[0,0,0,1,1],                         #training data\n",
    "                 [0,0,1,0,1],\n",
    "                 [0,1,0,0,1],\n",
    "                 [0,1,0,1,0],\n",
    "                 [0,1,1,0,0],\n",
    "                 [0,1,1,1,1],\n",
    "                 [1,0,0,0,1],\n",
    "                 [1,0,0,1,0],\n",
    "                 [1,0,1,1,1],\n",
    "                 [1,1,1,1,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9773bb63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 5)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7e12eae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(data[:,:-1])             #seperating labels from other features.\n",
    "Y = np.array(data[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "bb0e81c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = 2*Y -1                             #making labels 0,1 to -1,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5a32170e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:[0 0 0 1]    y:1\n",
      "x:[0 0 1 0]    y:1\n",
      "x:[0 1 0 0]    y:1\n",
      "x:[0 1 0 1]    y:-1\n",
      "x:[0 1 1 0]    y:-1\n",
      "x:[0 1 1 1]    y:1\n",
      "x:[1 0 0 0]    y:1\n",
      "x:[1 0 0 1]    y:-1\n",
      "x:[1 0 1 1]    y:1\n",
      "x:[1 1 1 1]    y:-1\n"
     ]
    }
   ],
   "source": [
    "for x,y in zip(X,Y):\n",
    "    print(f'x:{x}    y:{y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1482e269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [[[ 0.00064837 -0.01176363  0.00757532]\n",
      "  [-0.00217329  0.00377365  0.01429097]\n",
      "  [ 0.00820614  0.02755201 -0.0051022 ]\n",
      "  [ 0.00075407 -0.01243131 -0.01678522]]\n",
      "\n",
      " [[ 0.00685795 -0.02222703  0.02183569]\n",
      "  [ 0.00159701  0.0055386  -0.01232673]\n",
      "  [ 0.01301957  0.00513228  0.00736791]\n",
      "  [ 0.01150375  0.00057456  0.00676543]]]\n",
      "Bias:  0.0\n"
     ]
    }
   ],
   "source": [
    "#np.random.seed(7)\n",
    "num_qubits = 4\n",
    "num_layers = 2\n",
    "weights_init = 0.01 * np.random.randn(num_layers, num_qubits, 3, requires_grad=True)   #std = 0.01, mean = 0\n",
    "bias_init = np.array(0.0, requires_grad=True)   #requires_grad=True here means that bias_init trm will be optimized during training\n",
    "\n",
    "print(\"Weights:\", weights_init)\n",
    "print(\"Bias: \", bias_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "26c622e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = NesterovMomentumOptimizer(0.01)            #0.01 is the learning rate\n",
    "batch_size = 5                                   #taking a batch size of 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "acfdadcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter : 1 | Cost : 2.0098 | Accuracy : 0.500\n",
      "Iter : 2 | Cost : 2.0195 | Accuracy : 0.500\n",
      "Iter : 3 | Cost : 2.0202 | Accuracy : 0.500\n",
      "Iter : 4 | Cost : 2.0243 | Accuracy : 0.500\n",
      "Iter : 5 | Cost : 2.0234 | Accuracy : 0.500\n",
      "Iter : 6 | Cost : 2.0181 | Accuracy : 0.500\n",
      "Iter : 7 | Cost : 2.0062 | Accuracy : 0.500\n",
      "Iter : 8 | Cost : 1.9879 | Accuracy : 0.500\n",
      "Iter : 9 | Cost : 1.9720 | Accuracy : 0.500\n",
      "Iter : 10 | Cost : 1.9618 | Accuracy : 0.500\n",
      "Iter : 11 | Cost : 1.9602 | Accuracy : 0.500\n",
      "Iter : 12 | Cost : 1.9662 | Accuracy : 0.500\n",
      "Iter : 13 | Cost : 1.9797 | Accuracy : 0.500\n",
      "Iter : 14 | Cost : 1.9952 | Accuracy : 0.500\n",
      "Iter : 15 | Cost : 2.0126 | Accuracy : 0.500\n",
      "Iter : 16 | Cost : 2.0263 | Accuracy : 0.500\n",
      "Iter : 17 | Cost : 2.0390 | Accuracy : 0.500\n",
      "Iter : 18 | Cost : 2.0454 | Accuracy : 0.500\n",
      "Iter : 19 | Cost : 2.0600 | Accuracy : 0.500\n",
      "Iter : 20 | Cost : 2.0723 | Accuracy : 0.500\n",
      "Iter : 21 | Cost : 2.0763 | Accuracy : 0.500\n",
      "Iter : 22 | Cost : 2.0725 | Accuracy : 0.500\n",
      "Iter : 23 | Cost : 2.0474 | Accuracy : 0.500\n",
      "Iter : 24 | Cost : 2.0228 | Accuracy : 0.500\n",
      "Iter : 25 | Cost : 2.0040 | Accuracy : 0.500\n",
      "Iter : 26 | Cost : 1.9901 | Accuracy : 0.500\n",
      "Iter : 27 | Cost : 1.9825 | Accuracy : 0.500\n",
      "Iter : 28 | Cost : 1.9770 | Accuracy : 0.500\n",
      "Iter : 29 | Cost : 1.9749 | Accuracy : 0.500\n",
      "Iter : 30 | Cost : 1.9756 | Accuracy : 0.500\n",
      "Iter : 31 | Cost : 1.9765 | Accuracy : 0.500\n",
      "Iter : 32 | Cost : 1.9778 | Accuracy : 0.500\n",
      "Iter : 33 | Cost : 1.9750 | Accuracy : 0.500\n",
      "Iter : 34 | Cost : 1.9667 | Accuracy : 0.500\n",
      "Iter : 35 | Cost : 1.9615 | Accuracy : 0.500\n",
      "Iter : 36 | Cost : 1.9600 | Accuracy : 0.500\n",
      "Iter : 37 | Cost : 1.9597 | Accuracy : 0.500\n",
      "Iter : 38 | Cost : 1.9603 | Accuracy : 0.500\n",
      "Iter : 39 | Cost : 1.9606 | Accuracy : 0.500\n",
      "Iter : 40 | Cost : 1.9611 | Accuracy : 0.500\n",
      "Iter : 41 | Cost : 1.9627 | Accuracy : 0.500\n",
      "Iter : 42 | Cost : 1.9651 | Accuracy : 0.500\n",
      "Iter : 43 | Cost : 1.9682 | Accuracy : 0.500\n",
      "Iter : 44 | Cost : 1.9720 | Accuracy : 0.500\n",
      "Iter : 45 | Cost : 1.9725 | Accuracy : 0.500\n",
      "Iter : 46 | Cost : 1.9774 | Accuracy : 0.500\n",
      "Iter : 47 | Cost : 1.9803 | Accuracy : 0.500\n",
      "Iter : 48 | Cost : 1.9767 | Accuracy : 0.500\n",
      "Iter : 49 | Cost : 1.9781 | Accuracy : 0.500\n",
      "Iter : 50 | Cost : 1.9846 | Accuracy : 0.500\n"
     ]
    }
   ],
   "source": [
    "weights = weights_init\n",
    "bias = bias_init\n",
    "\n",
    "for i in range(50):\n",
    "    batch_index = np.random.randint(0, len(X), (batch_size,))  #creates indices and send this indices to next line and\n",
    "    X_batch = X[batch_index]                #X_batch contains like [X[batch_index1], X[batch_index2],...]\n",
    "    Y_batch = Y[batch_index]\n",
    "    weights, bias = opt.step(cost, weights, bias, X=X_batch, Y=Y_batch)\n",
    "    \n",
    "    predictions = [np.sign(variational_calssifier(weights,bias,x)) for x in X]\n",
    "    #print(predictions)  using all x in X\n",
    "    current_cost = cost(weights, bias, X, Y)\n",
    "    \n",
    "    accuracy = acc(Y, predictions)\n",
    "    \n",
    "    print(f\"Iter : {i+1} | Cost : {current_cost:0.4f} | Accuracy : {accuracy:0.3f}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4ec2a2a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(-1., requires_grad=True),\n",
       " tensor(1., requires_grad=True),\n",
       " tensor(-1., requires_grad=True),\n",
       " tensor(1., requires_grad=True),\n",
       " tensor(-1., requires_grad=True),\n",
       " tensor(1., requires_grad=True),\n",
       " tensor(-1., requires_grad=True),\n",
       " tensor(1., requires_grad=True),\n",
       " tensor(1., requires_grad=True),\n",
       " tensor(-1., requires_grad=True)]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions      #predictions of the last iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "bb9b7583",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.array([[0,0,0,0,0],               #test data\n",
    "                 [0,0,1,1,0],\n",
    "                 [1,0,1,0,0],\n",
    "                 [1,1,1,0,1],\n",
    "                 [1,1,0,0,0],\n",
    "                 [1,1,0,1,1],\n",
    "                 [0,1,0,1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ca4b44d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(test_data[:,:-1])             #seperating the labels\n",
    "Y_test = np.array(test_data[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "90f45502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:[0 0 0 0]    y:0\n",
      "x:[0 0 1 1]    y:0\n",
      "x:[1 0 1 0]    y:0\n",
      "x:[1 1 1 0]    y:1\n",
      "x:[1 1 0 0]    y:0\n",
      "x:[1 1 0 1]    y:1\n",
      "x:[0 1 0 1]    y:1\n"
     ]
    }
   ],
   "source": [
    "for x,y in zip(X_test,Y_test):\n",
    "    print(f'x:{x}    y:{y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0842d34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = Y_test*2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "94abf387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = [0 0 0 0], y = -1, pred=1.0\n",
      "x = [0 0 1 1], y = -1, pred=-1.0\n",
      "x = [1 0 1 0], y = -1, pred=-1.0\n",
      "x = [1 1 1 0], y = 1, pred=1.0\n",
      "x = [1 1 0 0], y = -1, pred=1.0\n",
      "x = [1 1 0 1], y = 1, pred=-1.0\n",
      "x = [0 1 0 1], y = 1, pred=1.0\n",
      "Accuracy on unseen data : 0.571\n"
     ]
    }
   ],
   "source": [
    "predictions_test = [np.sign(variational_calssifier(weights, bias, x)) for x in X_test]\n",
    "\n",
    "for x,y,p in zip(X_test, Y_test, predictions_test):\n",
    "    print(f\"x = {x}, y = {y}, pred={p}\")\n",
    "\n",
    "acc_test = acc(Y_test, predictions_test)\n",
    "\n",
    "print(f\"Accuracy on unseen data : {acc_test:0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe92572",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
